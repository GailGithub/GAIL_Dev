#   tolerance.  The default values are abstol=1e-2 and alpha=1%. Input
#   Yrand is a function handle that accepts a positive integer input n and
#   returns an n x 1 vector of IID instances of the random variable Y.
#
#   Input Arguments
#
#     Yrand --- the function for generating n IID instances of a random
#     variable Y whose mean we want to estimate. Y is often defined as a
#     function of some random variable X with a simple distribution. The
#     input of Yrand should be the number of random variables n, the output
#     of Yrand should be n function values. For example, if Y = X.^2 where X
#     is a standard uniform random variable, then one may define Yrand =
#     @(n) rand(n,1).^2.
#
#     abstol --- the absolute error tolerance, which should be
#     positive, default value is 1e-2.
#
#     alpha --- the uncertainty, which should be a small positive
#     percentage. The default value is 1%.
#
#     nSig --- the number of samples used to compute the sample variance
#
#     fudge --- the standard deviation invlation factor
#
#   Output Arguments
#
#     tmu --- the estimated mean of Y.
#
#     out_param.ntot --- total sample used.
#
#     out_param.var --- the sample variance.
#
#     out_param.time --- the time elapsed in seconds.
#
#This is a heuristic algorithm based on a Central Limit Theorem
#approximation
#Default Values
#fudge = 1.2; variance inflation factor
#nSig = 1e2; number of samples to estimate variance
#alpha = 0.01; uncertainty
#abstol = 0.01; absolute error tolerance
#Yrand = @(n) rand(n,1); random number generator
meanMC_CLT = function(Yrand = function(n) {runif(n)},abstol = 0.01,alpha = 0.01,nSig = 1e2,fudge = 1.2) {
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig);# get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
nmu = max(1,ceiling((-qnorm(alpha)*sig0up/abstol)^2));
#number of samples needed for mean
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu = mean(Yrand(nmu)); #estimated mean
out_param.ntot = nSig + nmu; #total samples required
out_param.time = proc.time() - tstart; #elapsed time
return(c(tmu,out_param.ntot,out_param.time))
}
meanMC_CLT
meanMC_CLT()
luana=function(a=4){
c=a+2
return(c)
}
luana
luana(4)
luana()
luana=function(a=4){
c=a+2
return(c,a)
}
luana()
luana=function(a=4){
c=a+2
return(c)
}
anthony=function(c){
c
return(c)
}
anthony()
luana()
anthony()
luana=function(a=4){
c=a+2
return(c)
}
anthony=function(c){
a=c+1
return(c)
}
?proc.time
1e2
?stopifnot
stopifnot(1 == 1, all.equal(pi, 3.14159265), 1 < 2) # all TRUE
m <- matrix(c(1,3,3,1), 2, 2)
stopifnot(m == t(m), diag(m) == rep(1, 2)) # all(.) |=>  TRUE
op <- options(error = expression(NULL))
# "disable stop(.)"  << Use with CARE! >>
stopifnot(all.equal(pi, 3.141593),  2 < 2, all(1:10 < 12), "a" < "b")
stopifnot(all.equal(pi, 3.1415927), 2 < 2, all(1:10 < 12), "a" < "b")
options(op)  # revert to previous error handler
?stop
?stopifnot
?fzero
??fzero
?uniroot
stdnormcdf = function (z) {
# this function is to define cumulative distribution function (CDF) of the
# standard normal distribution.
p = 0.5*(2*pnorm(-z/sqrt(2)*sqrt(2),lower=FALSE))
# Use the complementary error function, rather than .5*(1+erf(z/sqrt(2))),
# to produce accurate near-zero results for large negative x.
return(p)
}
stdnormcdf(2)
stdnormcdf = function (z) {
# this function is to define cumulative distribution function (CDF) of the
# standard normal distribution.
p = 0.5*(2*pnorm(-z,lower=FALSE))
# Use the complementary error function, rather than .5*(1+erf(z/sqrt(2))),
# to produce accurate near-zero results for large negative x.
return(p)
}
stdnormcdf(2)
qnorm(0.23)
library(pracma)
#MEANMCabs_g_abbr Monte Carlo method to estimate the mean of a random variable
#
#   tmu = MEANMCabs_g_abbr(Yrand,abstol,alpha,nSig,fudge) estimates the mean, mu, of a random variable Y to
#   within a specified error tolerance, i.e., | mu - tmu | <= abstol with
#   probability at least 1-alpha, where abstol is the absolute error
#   tolerance.  The default values are abstol=1e-2 and alpha=1%. Input
#   Yrand is a function handle that accepts a positive integer input n and
#   returns an n x 1 vector of IID instances of the random variable Y.
#
#   Input Arguments
#
#     Yrand --- the function for generating n IID instances of a random
#     variable Y whose mean we want to estimate. Y is often defined as a
#     function of some random variable X with a simple distribution. The
#     input of Yrand should be the number of random variables n, the output
#     of Yrand should be n function values. For example, if Y = X.^2 where X
#     is a standard uniform random variable, then one may define Yrand =
#     @(n) rand(n,1).^2.
#
#     abstol --- the absolute error tolerance, which should be
#     positive, default value is 1e-2.
#
#     alpha --- the uncertainty, which should be a small positive
#     percentage. The default value is 1%.
#
#     nSig --- the number of samples used to compute the sample variance. The
#     default value is 1e2
#
#     fudge --- the standard deviation invlation factor.  The default value
#     is 1e2
#
#   Output Arguments
#
#     tmu --- the estimated mean of Y.
#
#     out_param.ntot --- total sample used.
#
#     out_param.var --- the sample variance.
#
#     out_param.time --- the time elapsed in seconds.
#
#This is a heuristic algorithm based on a Central Limit Theorem
#approximation
meanMCabs_g_abbr = function (Yrand = function(n) {runif(n)^2},abstol=0.01,alpha=0.01,nSig=1e2,fudge=1.2){
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
out_param.abstol = abstol;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig); # get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
alpha1 = 1-sqrt(1-out_param.alpha); # one side of the uncertainty
out_param.kurtmax = (out_param.nSig-3)/(out_param.nSig-1)
+ ((alpha1*out_param.nSig)/(1-alpha1))*(1-1/out_param.fudge^2)^2;
toloversig = out_param.abstol/sig0up;
# absolute error tolerance over sigma
ncheb = ceiling(1/(alpha1*toloversig^2));
# use Chebyshev inequality to estimate n
A=18.1139;
A1=0.3328;
A2=0.429; # three constants in Berry-Esseen inequality
M3upper=out_param.kurtmax^(3/4); #using Jensen inequality to
#                                       bound the third moment
BEfun= function(logsqrtn) {pnorm(-exp(logsqrtn)*toloversig)+
exp(-logsqrtn)*min(A1*(M3upper+A2),
A*M3upper/(1+(exp(logsqrtn)*toloversig)^3))- alpha1/2;
}
# Berry-Esseen Inequality
logsqrtnCLT=log(qnorm(1-alpha1/2)/toloversig);
nmu=min(ncheb,ceiling(exp(2*fzero(BEfun,logsqrtnCLT)$x)));
#get the min n (used to estimate mu) by using cheb and BEfun
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu=mean(Yrand(nmu)); #estimated mean
out_param.ntot=nSig+nmu; #total samples required
out_param.time=proc.time()-tstart; #elapsed time
out_param.time=unname(out_param.time)
return(c("tmu"= tmu,"out_param.ntot" = out_param.ntot,"out_param.var" = out_param.var,"out_param.time" = out_param.time[3]))
}
meanMCAabs_g_abbr()
meanMCabs_g_abbr()
meanMCabs__abbr([1])
meanMCabs__abbr(){1}
meanMCabs__abbr()[1]
meanMCabs__abbr()
meanMCabs_g_abbr()
meanMCabs_g_abbr()[1]
meanMCabs_g_abbr()[2]
meanMCabs_g_abbr()["tmu"]
meanMCabs_g_abbr()["out_param.ntot"]
meanMCabs_g_abbr()["out_param.time"]
library(pracma)
#MEANMCabs_g_abbr Monte Carlo method to estimate the mean of a random variable
#
#   tmu = MEANMCabs_g_abbr(Yrand,abstol,alpha,nSig,fudge) estimates the mean, mu, of a random variable Y to
#   within a specified error tolerance, i.e., | mu - tmu | <= abstol with
#   probability at least 1-alpha, where abstol is the absolute error
#   tolerance.  The default values are abstol=1e-2 and alpha=1%. Input
#   Yrand is a function handle that accepts a positive integer input n and
#   returns an n x 1 vector of IID instances of the random variable Y.
#
#   Input Arguments
#
#     Yrand --- the function for generating n IID instances of a random
#     variable Y whose mean we want to estimate. Y is often defined as a
#     function of some random variable X with a simple distribution. The
#     input of Yrand should be the number of random variables n, the output
#     of Yrand should be n function values. For example, if Y = X.^2 where X
#     is a standard uniform random variable, then one may define Yrand =
#     @(n) rand(n,1).^2.
#
#     abstol --- the absolute error tolerance, which should be
#     positive, default value is 1e-2.
#
#     alpha --- the uncertainty, which should be a small positive
#     percentage. The default value is 1%.
#
#     nSig --- the number of samples used to compute the sample variance. The
#     default value is 1e2
#
#     fudge --- the standard deviation invlation factor.  The default value
#     is 1e2
#
#   Output Arguments
#
#     tmu --- the estimated mean of Y.
#
#     out_param.ntot --- total sample used.
#
#     out_param.var --- the sample variance.
#
#     out_param.time --- the time elapsed in seconds.
#
#This is a heuristic algorithm based on a Central Limit Theorem
#approximation
meanMCabs_g_abbr = function (Yrand = function(n) {runif(n)^2},abstol=0.01,alpha=0.01,nSig=1e2,fudge=1.2){
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
out_param.abstol = abstol;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig); # get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
alpha1 = 1-sqrt(1-out_param.alpha); # one side of the uncertainty
out_param.kurtmax = (out_param.nSig-3)/(out_param.nSig-1)
+ ((alpha1*out_param.nSig)/(1-alpha1))*(1-1/out_param.fudge^2)^2;
toloversig = out_param.abstol/sig0up;
# absolute error tolerance over sigma
ncheb = ceiling(1/(alpha1*toloversig^2));
# use Chebyshev inequality to estimate n
A=18.1139;
A1=0.3328;
A2=0.429; # three constants in Berry-Esseen inequality
M3upper=out_param.kurtmax^(3/4); #using Jensen inequality to
#                                       bound the third moment
BEfun= function(logsqrtn) {pnorm(-exp(logsqrtn)*toloversig)+
exp(-logsqrtn)*min(A1*(M3upper+A2),
A*M3upper/(1+(exp(logsqrtn)*toloversig)^3))- alpha1/2;
}
# Berry-Esseen Inequality
logsqrtnCLT=log(qnorm(1-alpha1/2)/toloversig);
nmu=min(ncheb,ceiling(exp(2*fzero(BEfun,logsqrtnCLT)$x)));
#get the min n (used to estimate mu) by using cheb and BEfun
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu=mean(Yrand(nmu)); #estimated mean
out_param.ntot=nSig+nmu; #total samples required
out_param.time=proc.time()-tstart; #elapsed time
out_param.time=unname(out_param.time)
return(c("tmu"= tmu,"out_param.ntot" = out_param.ntot,"out_param.var" = out_param.var,"out_param.time" = out_param.time[3]))
}
meanMCabs_g_abbr()
meanMCabs_g_abbr()
meanMCabs_g_abbr()
meanMCabs_g_abbr()
library(pracma)
#MEANMCabs_g_abbr Monte Carlo method to estimate the mean of a random variable
#
#   tmu = MEANMCabs_g_abbr(Yrand,abstol,alpha,nSig,fudge) estimates the mean, mu, of a random variable Y to
#   within a specified error tolerance, i.e., | mu - tmu | <= abstol with
#   probability at least 1-alpha, where abstol is the absolute error
#   tolerance.  The default values are abstol=1e-2 and alpha=1%. Input
#   Yrand is a function handle that accepts a positive integer input n and
#   returns an n x 1 vector of IID instances of the random variable Y.
#
#   Input Arguments
#
#     Yrand --- the function for generating n IID instances of a random
#     variable Y whose mean we want to estimate. Y is often defined as a
#     function of some random variable X with a simple distribution. The
#     input of Yrand should be the number of random variables n, the output
#     of Yrand should be n function values. For example, if Y = X.^2 where X
#     is a standard uniform random variable, then one may define Yrand =
#     @(n) rand(n,1).^2.
#
#     abstol --- the absolute error tolerance, which should be
#     positive, default value is 1e-2.
#
#     alpha --- the uncertainty, which should be a small positive
#     percentage. The default value is 1%.
#
#     nSig --- the number of samples used to compute the sample variance. The
#     default value is 1e2
#
#     fudge --- the standard deviation invlation factor.  The default value
#     is 1e2
#
#   Output Arguments
#
#     tmu --- the estimated mean of Y.
#
#     out_param.ntot --- total sample used.
#
#     out_param.var --- the sample variance.
#
#     out_param.time --- the time elapsed in seconds.
#
#This is a heuristic algorithm based on a Central Limit Theorem
#approximation
meanMCabs_g_abbr = function (Yrand = function(n) {runif(n)^2},abstol=0.01,alpha=0.01,nSig=1e2,fudge=1.2){
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
out_param.abstol = abstol;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig); # get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
alpha1 = 1-sqrt(1-out_param.alpha); # one side of the uncertainty
out_param.kurtmax = (out_param.nSig-3)/(out_param.nSig-1)
+ ((alpha1*out_param.nSig)/(1-alpha1))*(1-1/out_param.fudge^2)^2;
toloversig = out_param.abstol/sig0up;
# absolute error tolerance over sigma
ncheb = ceiling(1/(alpha1*toloversig^2));
# use Chebyshev inequality to estimate n
A=18.1139;
A1=0.3328;
A2=0.429; # three constants in Berry-Esseen inequality
M3upper=out_param.kurtmax^(3/4); #using Jensen inequality to
#                                       bound the third moment
BEfun= function(logsqrtn) {pnorm(-exp(logsqrtn)*toloversig)+
exp(-logsqrtn)*min(A1*(M3upper+A2),
A*M3upper/(1+(exp(logsqrtn)*toloversig)^3))- alpha1/2;
}
# Berry-Esseen Inequality
logsqrtnCLT=log(qnorm(1-alpha1/2)/toloversig);
nmu=min(ncheb,ceiling(exp(2*fzero(BEfun,logsqrtnCLT)$x)));
#get the min n (used to estimate mu) by using cheb and BEfun
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu=mean(Yrand(nmu)); #estimated mean
out_param.ntot=nSig+nmu; #total samples required
out_param.time=proc.time()-tstart; #elapsed time
out_param.time=unname(out_param.time)
return(c("tmu"= tmu,"out_param.ntot" = out_param.ntot,"out_param.var" = out_param.var,"out_param.time" = out_param.time[3]))
}
meanMCabs_g_abbr()
?proc.time
meanMCabs_g_abbr([tmu])
meanMCabs_g_abbr(["tmu"])
meanMCabs_g_abbr()[tmu]
meanMCabs_g_abbr()["tmu"]
meanMCabs_g_abbr()["tmu","out_param.var"]
meanMCabs_g_abbr()["tmu";"out_param.var"]
meanMCabs_g_abbr()[c("tmu","out_param.var")]
2*meanMCabs_g_abbr()["tmu"]
2*meanMCabs_g_abbr()[c("tmu","out_param.var")]
?fzero
meanMCabs_g_abbr()["alpha"]
meanMCabs_g_abbr()["out_param.alpha"]
meanMCabs_g_abbr()["tmu"]
?list
library(pracma)
meanMCabs_g_abbr = function (Yrand = function(n) {runif(n)^2},abstol=0.01,alpha=0.01,nSig=1e2,fudge=1.2){
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
out_param.abstol = abstol;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig); # get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
alpha1 = 1-sqrt(1-out_param.alpha); # one side of the uncertainty
out_param.kurtmax = (out_param.nSig-3)/(out_param.nSig-1)
+ ((alpha1*out_param.nSig)/(1-alpha1))*(1-1/out_param.fudge^2)^2;
toloversig = out_param.abstol/sig0up;
# absolute error tolerance over sigma
ncheb = ceiling(1/(alpha1*toloversig^2));
# use Chebyshev inequality to estimate n
A=18.1139;
A1=0.3328;
A2=0.429; # three constants in Berry-Esseen inequality
M3upper=out_param.kurtmax^(3/4); #using Jensen inequality to
#                                       bound the third moment
BEfun= function(logsqrtn) {pnorm(-exp(logsqrtn)*toloversig)+
exp(-logsqrtn)*min(A1*(M3upper+A2),
A*M3upper/(1+(exp(logsqrtn)*toloversig)^3))- alpha1/2;
}
# Berry-Esseen Inequality
logsqrtnCLT=log(qnorm(1-alpha1/2)/toloversig);
nmu=min(ncheb,ceiling(exp(2*fzero(BEfun,logsqrtnCLT)$x)));
#get the min n (used to estimate mu) by using cheb and BEfun
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu=mean(Yrand(nmu)); #estimated mean
out_param.ntot=nSig+nmu; #total samples required
out_param.time=proc.time()-tstart; #elapsed time
out_param.time=unname(out_param.time)
return(list(tmu,out_param.ntot,out_param.var,out_param.time[3]))
}
meanMCabs_g_abbr()
library(pracma)
meanMCabs_g_abbr = function (Yrand = function(n) {runif(n)^2},abstol=0.01,alpha=0.01,nSig=1e2,fudge=1.2){
nMax=1e8; #maximum number of samples allowed.
out_param.alpha = alpha; #save the input parameters to a structure
out_param.fudge = fudge;
out_param.nSig = nSig;
out_param.abstol = abstol;
tstart = proc.time(); #start the clock
Yval = Yrand(nSig); # get samples to estimate variance
out_param.var = var(Yval); #calculate the sample variance--stage 1
sig0 = sqrt(out_param.var); #standard deviation
sig0up = out_param.fudge*sig0; #upper bound on the standard deviation
alpha1 = 1-sqrt(1-out_param.alpha); # one side of the uncertainty
out_param.kurtmax = (out_param.nSig-3)/(out_param.nSig-1)
+ ((alpha1*out_param.nSig)/(1-alpha1))*(1-1/out_param.fudge^2)^2;
toloversig = out_param.abstol/sig0up;
# absolute error tolerance over sigma
ncheb = ceiling(1/(alpha1*toloversig^2));
# use Chebyshev inequality to estimate n
A=18.1139;
A1=0.3328;
A2=0.429; # three constants in Berry-Esseen inequality
M3upper=out_param.kurtmax^(3/4); #using Jensen inequality to
#                                       bound the third moment
BEfun= function(logsqrtn) {pnorm(-exp(logsqrtn)*toloversig)+
exp(-logsqrtn)*min(A1*(M3upper+A2),
A*M3upper/(1+(exp(logsqrtn)*toloversig)^3))- alpha1/2;
}
# Berry-Esseen Inequality
logsqrtnCLT=log(qnorm(1-alpha1/2)/toloversig);
nmu=min(ncheb,ceiling(exp(2*fzero(BEfun,logsqrtnCLT)$x)));
#get the min n (used to estimate mu) by using cheb and BEfun
stopifnot(nmu<nMax)
#don't exceed sample budget
tmu=mean(Yrand(nmu)); #estimated mean
out_param.ntot=nSig+nmu; #total samples required
out_param.time=proc.time()-tstart; #elapsed time
out_param.time=unname(out_param.time)
return(list("tmu"= tmu,"out_param.ntot" = out_param.ntot,"out_param.var" = out_param.var,"out_param.time" = out_param.time[3]))
}
meanMCabs_g_abbr()
meanMCabs_g_abbr()$tmu
meanMCabs_g_abbr()$c("tmu","out_param.var")
meanMCabs_g_abbr()$tmu,out_param.var
c(meanMCabs_g_abbr()$tmu,meanMCabs_g_abbr()out_param.var)
c(meanMCabs_g_abbr()$tmu,meanMCabs_g_abbr()$out_param.var)
2*meanMCabs_g_abbr()$tmu
2*c(meanMCabs_g_abbr()$tmu,meanMCabs_g_abbr()$out_param.var)
meanMCabs_g_abbr(Yrand = function(n) {runif(n)})
meanMCabs_g_abbr(abstol=0.015,alpha=0.015)
setwd("C:/Users/Luana/Desktop/Research Chicago/GAIL_Dev/GAIL_R")
setwd("C:/Users/Luana/Desktop/Research Chicago/GAIL_Dev/GAIL_R")
source("meanMC_CLT.R")
meandist = meanMC_CLT(distfun,0.02)
distfun = function(n){sqrt(rowSums((matrix(runif(n*2),n,2) - matrix(runif(n*2),n,2))^2))}
meandist = mean(distfun(1e6))
meandist
meandist = meanMC_CLT(distfun,0.02)
meandist
?source
?matrix
